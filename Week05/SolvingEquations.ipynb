{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Supporting textbook chapters: 6.1, 6.2, 6.3*\n",
    "\n",
    "**Topics:**\n",
    "* Solving linear systems\n",
    "* Roots of nonlinear equations\n",
    "* Minima: golden ratio search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Solving linear systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gaussian elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* In linear algebra courses, you learn to solve linear systems of the form\n",
    "$$A x = v$$\n",
    "using Gaussian elimination.\n",
    "* This works pretty well in many cases. Let's do an example based on Newman's `gausselim.py`, for\n",
    "$$A =\n",
    "\\begin{bmatrix}\n",
    "6 & 5 \\\\\n",
    "4 & 3\n",
    "\\end{bmatrix}, \\qquad v = \\binom{2}{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Refresher on Gaussian elimination (how `gausselim` works): the equation we need to solve is\n",
    "$$\\begin{bmatrix}\n",
    "6 & 5 \\\\\n",
    "4 & 3\n",
    "\\end{bmatrix}\\binom{x_1}{x_2} = \\binom{2}{1}$$\n",
    "and therefore\n",
    "$$6x_1 + 5x_2 = 2,$$\n",
    "$$4x_1 + 3x_2 = 1$$\n",
    "1. Divide 1st line by 1st (top-left) coefficient:\n",
    "    $$x_1 + \\frac56x_2 = \\frac13,$$\n",
    "    $$4x_1 + 3x_2 = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2. $4\\times \\text{1st eqn} - \\text{2nd eqn} = \\text{new 2nd eqn.}$:\n",
    "    $$x_1 + \\frac56x_2 = \\frac13,$$\n",
    "    $$0x_1 + \\frac13x_2 = \\frac13,$$\n",
    "    and $x_2=1$.\n",
    "    More eqns $\\Rightarrow$ cancel all 1st coefficents of each line similarly.\n",
    "    \n",
    "3. (if more eqns: repeat from 2nd line to eliminate all 2nd coefficients below, and so on...)\n",
    "\n",
    "4. (or 3.) Back-substitute: $x_2=1 \\Rightarrow x_1 + 5/6 = 1/3 \\Rightarrow x_1 = -1/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# textbook's Gaussian Elimination code\n",
    "from numpy import array, empty\n",
    "\n",
    "def gausselim(A, v):\n",
    "    N = len(v)\n",
    "    # Gaussian elimination\n",
    "    for m in range(N):\n",
    "        # Divide by the diagonal element\n",
    "        div = A[m, m]\n",
    "        A[m, :] /= div\n",
    "        v[m] /= div\n",
    "        # Now subtract from the lower rows\n",
    "        for i in range(m+1, N):\n",
    "            mult = A[i, m]\n",
    "            A[i, :] -= mult*A[m, :]\n",
    "            v[i] -= mult*v[m]\n",
    "    # Backsubstitution\n",
    "    x = empty(N, float)\n",
    "    for m in range(N-1, -1, -1):\n",
    "        x[m] = v[m]\n",
    "        for i in range(m+1, N):\n",
    "            x[m] -= A[m, i]*x[i]\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5  1. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A1 = np.array([[6, 5], [4, 3]], float)  \n",
    "V1 = np.array([2, 1], float)\n",
    "\n",
    "gausselim(A1, V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When Gaussian elimination breaks down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The example below is a valid system but the original code will \"break\".\n",
    "$$A =\n",
    "\\begin{bmatrix}\n",
    "10^{-20} & 1 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix}, \\qquad v = \\binom{1}{0}.$$\n",
    "In theory, $\\displaystyle x \\approx \\binom{-1}{1}$. But according to `gausselim`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "A2 = np.array([[1e-20, 1], [1, 1]], float)  # I imported np earlier\n",
    "V2 = np.array([1, 0], float)\n",
    "\n",
    "gausselim(A2, V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Don't divide by (close to) zero!\n",
    "* Had the top-left number actually been zero, Python would have thrown a `ZeroDivisionError`,\n",
    "* with $10^{-20}<$ machine precision, no tripwire from Python, but rounding errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy gives the same wrong result!\n",
    "np.linalg.solve(A2, V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150/930078458.py:3: LinAlgWarning: Ill-conditioned matrix (rcond=1e-40): result may not be accurate.\n",
      "  la.solve(A2, V2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SciPy does not give a better result either ... but at least it gives a warning!\n",
    "import scipy.linalg as la\n",
    "la.solve(A2, V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial pivoting: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Eliminates the issue of dividing by zero if diagonal entries become zero (or very close to zero)\n",
    "\n",
    "**Algorithm outline:**\n",
    "1. At $m^\\text{th}$ row, check to see which of the rows below has the largest $m^\\text{th}$ element (absolute value)\n",
    "    * Swap this row with the current $m^\\text{th}$ value\n",
    "    * Proceed with Gaussian elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1.]\n"
     ]
    }
   ],
   "source": [
    "A3 = np.array([[1, 1], [1e-20, 1]], float)  # swapped rows\n",
    "V3 = np.array([0, 1], float)  # need to swap this one too\n",
    "\n",
    "gausselim(A3, V3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## LU Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a system $Ax = f$ where $f$ depends on some parameter of a physical system. When you change the parameter, $f$ changes, but $A$ doesn't. You don't want to re-do the entire Gaussian Elimination procedure each time you changet the parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The steps in the Gaussian elimination will always be the same: only need to do it once, then store.\n",
    "\n",
    "Gaussian elimination on a matrix $A$ can be written as a series of matrix multiplications that yields $U = L_nL_{n-1}\\cdots L_0A$, where $U$ is upper triangular (i.e., result of Gaussian elimination):\n",
    "\n",
    "$$L^{-1} = L_n L_{n-1} \\cdots L_0 \\Rightarrow\\ Ax =  LUx = f.$$\n",
    "\n",
    "(see Newman pp. 222-224 for a $4\\times4$ example; easy but long)\n",
    "\n",
    "The decomposition\n",
    "$$\\boxed{LU = A}$$\n",
    "is called the \"LU decomposition\" of the matrix $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to use LU in practice\n",
    "\n",
    "* Suppose you know $L$, $U$ from $A$.\n",
    "* Then, $$Ax=f \\Leftrightarrow Ux=L^{-1}f.$$\n",
    "* Break down into **two triangular-matrix problems, $Ux=y$ and $Ly = f$**.\n",
    "* Triangular $\\Rightarrow$ back-substitution (pizza cake!)\n",
    "* This method is used by `numpy.linalg.solve(A, f)`\n",
    "* `scipy.linalg.lu_solve(scipy.linalg.lu_factor(A), f)` is equivalent to `numpy.linalg.solve(A, f)`, but intermediate steps give access to the decomposition and allow storage.\n",
    "* Once you've done the LU decomposition of $A$, you don't need to do it again $\\Rightarrow\\ f$ can change over and over, $Ly=f$ is staightforward, and so is $Ux=y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Issues with LU Decomposition\n",
    "\n",
    "LU Decomposition fails when $A$ is close to singular, due to rounding error again.\n",
    "\n",
    "For starters, take a matrix that is actually singular, e.g:\n",
    "$$A = \n",
    "\\begin{bmatrix}\n",
    "    1 & 2 \\\\ 2 & 4\n",
    "\\end{bmatrix}$$\n",
    "Depending on the RHS, we end up with either no solution, or one undetermined coefficient.\n",
    "\n",
    "$A\\binom{x_1}{x_2} = \\binom{3}{5}\\rightarrow $ can't have $x_1 + 2x_2 = 3$ and $= 5/2$ at the same time\n",
    "\n",
    "$A\\binom{x_1}{x_2} = \\binom{3}{6}\\rightarrow$ infinite number of solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, LU won't find a solution when there is none: not really a drawback.\n",
    "But what about \n",
    "$$A = \n",
    "\\begin{bmatrix}\n",
    "    1 & 2 \\\\ 2 & 4+\\delta\n",
    "\\end{bmatrix},$$\n",
    "with $\\delta$ very small compared to other coefficients? \n",
    "Not singular, but LU won't work if $\\delta$ is too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [2. 4.]]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(A)\n\u001b[1;32m      4\u001b[0m v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m], \u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# returns error if delta/4 < machine precision\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/linalg/linalg.py:400\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    398\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdd->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    399\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 400\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/linalg/linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "delta = 1e-16\n",
    "A = np.array([[1, 2], [2, 4+delta]], float)\n",
    "print(A)\n",
    "v = np.array([3, 5], float)\n",
    "np.linalg.solve(A, v)  # returns error if delta/4 < machine precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## QR decomposition for eigensystems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Looking for $\\lambda$'s and $v$'s such that $Av = \\lambda v$, \n",
    "with $v$ eigenvector, $\\lambda$ eigenvalue\n",
    "\n",
    "Or for $\\Lambda$ and $V$ such that $AV = V\\Lambda$, \n",
    "with $V$ orthonormal matrix of eigenvectors, $\\Lambda$ diagonal matrix of eigenvalues\n",
    "\n",
    "If $A$ is square and **either symmetric-real or Hermitian** (complex), we can solve this problem with a QR decomposition.\n",
    "\n",
    "Don't get hung up on the details of the algorithm description below. Recall that it's iterative, and that it can break sometimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QR algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Gram-Schmidt on columns of $A$ (Exercise 6.8) $\\Rightarrow$ matrix of orthonormal basis of column vectors $Q$\n",
    "* Denote QR decomposition of $A$ as $A = QR$, where $R$ is upper-triangular\n",
    "* $Q$ orthonormal $\\Rightarrow\\ Q^TQ=I\\ \\Rightarrow\\ R = Q^TA$.\n",
    "\n",
    "Iterate:\n",
    "* $A_1 = RQ = Q^TAQ$ --------------> Define $A_1$\n",
    "* $A_1 = Q_1R_1$ ------------------------->  QR decomposition of $A_1$\n",
    "* $A_2 = R_1Q_1 = \\underbrace{Q_1^T\\underbrace{Q^TA}_{R}Q}_{R_1}Q_1$ --> Define $A_2$\n",
    "* $A_2 = Q_2R_2$ -------------------------> QR decomposition of $A_2$\n",
    "* $A_3 = \\dots$ \n",
    "... and so on, until obtaining an $A_k$ such that all off-diagnonal terms are small enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Eventually, \"it can be proven\" that this iteration converges to a (near-)diagonal output $$A_k = \\underbrace{(Q_k^T\\cdots Q_1^TQ^T)}_{V^T\\ (\\text{because}\\ Q_i^TQ_i = I)}A\\underbrace{(QQ_1\\cdots Q_k)}_V$$\n",
    "\n",
    "$$\\Rightarrow\\ A_k  = V^TAV\\ \\Rightarrow\\ \\boxed{AV = VA_k}.$$\n",
    "\n",
    "* diagonal entries of $A_k$ (off-diagonal entries are now tiny) are the eigenvalues: $\\boxed{A_k=\\Lambda}$.\n",
    "* The eigenvectors are the columns of $\\boxed{V=QQ_1\\cdots Q_k}$\n",
    "\n",
    "\n",
    "\n",
    "`numpy.linalg` implements the QR algorithm in the `numpy.linalg.eigh` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using QR in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[2 1]\n",
      " [1 2]]\n",
      "\n",
      "eigenvalues:  [1. 3.]\n",
      "eigenvectors:\n",
      " [[-0.70710678  0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "\n",
      "AV:\n",
      " [[-0.70710678  2.12132034]\n",
      " [ 0.70710678  2.12132034]]\n",
      "VL:\n",
      " [[-0.70710678  2.12132034]\n",
      " [ 0.70710678  2.12132034]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, 1], [1, 2]])  # imported numpy as np earlier\n",
    "\n",
    "print('A:\\n', A)\n",
    "\n",
    "eig_vs, V = np.linalg.eigh(A)  # calculate eigenvalues & eigenvectors\n",
    "L = np.diag(eig_vs)  # np.diag constructs a diagonal array\n",
    "\n",
    "print('\\neigenvalues: ', eig_vs)\n",
    "print('eigenvectors:\\n', V)\n",
    "\n",
    "# we expect that AV = VD\n",
    "print('\\nAV:\\n', np.dot(A, V))\n",
    "print('VL:\\n', np.dot(V, L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When QR breaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* `eigh` takes only Hermitian or real symmetric matrices as input\n",
    "* What happens if we try a different (non-symmetric) matrix?\n",
    "\n",
    "$$ A =\n",
    "\\begin{bmatrix}\n",
    "2 & 3 \\\\\n",
    "1 & 2\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AV:\n",
      " [[0.70710678 3.53553391]\n",
      " [0.70710678 2.12132034]]\n",
      "VL:\n",
      " [[-0.70710678  2.12132034]\n",
      " [ 0.70710678  2.12132034]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2,3],[1,2]])\n",
    "eig_vs, V = np.linalg.eigh(A) # calculate eigenvalues & eigenvectors\n",
    "L = np.diag(eig_vs)  # np.diag constructs a diagonal array\n",
    "\n",
    "print('AV:\\n', np.dot(A, V))\n",
    "print('VL:\\n', np.dot(V, L)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Result above should show that with $A$ is not a symmetric matrix: $AV \\neq \\Lambda V$. There are less efficient algorithms that will work with non-symmetric $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AV:\n",
      " [[ 3.23205081 -0.23205081]\n",
      " [ 1.8660254   0.1339746 ]]\n",
      "VL:\n",
      " [[ 3.23205081 -0.23205081]\n",
      " [ 1.8660254   0.1339746 ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2,3],[1,2]])\n",
    "eig_vs, V = np.linalg.eig(A) # calculate eigenvalues & eigenvectors\n",
    "L = np.diag(eig_vs)  # np.diag constructs a diagonal array\n",
    "\n",
    "print('AV:\\n', np.dot(A, V))\n",
    "print('VL:\\n', np.dot(V, L)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finding roots of nonlinear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "The textbook discusses several methods. We'll summarize a few of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Relaxation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The guinea piggies' favourite method for everything!\n",
    "\n",
    "* Solving for $x$ in an equation $x = f(x)$\n",
    "* Guess an initial value $x_0$ and iterate until the function converges to a fixed point\n",
    "\n",
    "$$x_1 = f(x_0)$$\n",
    "$$x_2 = f(x_1)$$\n",
    "$$\\vdots$$\n",
    "\n",
    "* Caveat: Can only find *stable* fixed points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![https://commons.wikimedia.org/w/index.php?curid=2037027](Cosine_fixed_point.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Newton's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Solving for $x$ in $f(x) = 0$\n",
    "1. Start with some value $x_1$, calculate tangent $f'(x_1)$\n",
    "2. Travel along tangent line to intersection with $x$-axis at $x_2$\n",
    "3. Repeat (calculate tangent $f'(x_2)$, etc.)\n",
    "\n",
    "Mathematically:\n",
    "$$x_{n+1} = x_n-\\frac{f(x_n)}{f'(x_n)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![By Ralf Pfeifer CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=2268473](NewtonIteration_Ani.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using Newton's Method in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``Secant method\" variation on Newton's Method:** If analytic form of $f$ is unknown, calculate $f'(x)$ numerically\n",
    " * Suggest using forward or backward difference, to avoid re-computing yet another $f(x_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Pro:**\n",
    "* Much faster than relaxation\n",
    "\n",
    "**Cons:**\n",
    "* Need to know $f'$ (although this issue is addressed by the secant method)\n",
    "* Doesn't always converge\n",
    "    * need to have good initial guess (like relaxation),\n",
    "    * small $f'$ gives $x_{n+1}$ much farther away,\n",
    "    * sometimes, it just does not converge. Period. (e.g., fractals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bisection (or Binary Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Bracket a single root on either side of the zero of the function $(x_1,x_2)$\n",
    "* Use midpoint $x'$ as subsequent bracket \n",
    "* Choose brackets depending on the sign of the value at the midpoint; \n",
    "     - For this example, $f(x_1)>0$, $f(x') < 0$, so the next set of brackets is $(x_1,x')$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Textbook fig 6.3](bisect.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convergence and Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Pro:**\n",
    "* Incredibly easy to remember, therefore to implement\n",
    "* When there's a root, there's a way (no worries about converging towards at least *a* root)\n",
    "\n",
    "**Cons:**\n",
    "* Only works with a single bracketed root\n",
    "* Can't find \"double roots\" where $f(x)$ reaches but does not cross 0 (think $f(x)=x^2$)\n",
    "* Can't find even one root when there is an even number of roots.\n",
    "* Large sample intervals can \"miss\" roots\n",
    "* Slower than Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![](ConvergenceRoots.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finding minima/maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Again, there are several methods. We'll focus on the Golden Ratio search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Golden Ratio search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Similar to binary search: find minimum by shrinking intervals\n",
    "\n",
    "1. Start with 2 points $x_1, x_4$ bracketing the interval\n",
    "2. Choose 2 points $x_2,x_3$ inside the interval\n",
    "* Check which of $f(x_2)$ and $f(x_3)$ is lower to determine new brackets\n",
    "    * In this example: $f(x_2)<f(x_3) \\Rightarrow$ new interval is $[x_1, x_3]$\n",
    "\n",
    "Use the golden ratio to determine the most optimal placement of the internal points $x_1, x_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Textbook's fig. 6.9](fig6-9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why the Golden Ratio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Interior points $x_2$, $x_3$ must be symmetric about the midpoint of the interval (why favour one side vs. the other?)\n",
    "* If you place interior points close (distance $\\epsilon$) to the centre of interval:\n",
    "    * you'll divide your search interval by $\\approx2$ (very good), but \n",
    "    * next step will be difficult: new \"interior\" point will be bar from new centre, next step will only divide the search interval by $\\approx 1-\\epsilon$ (very bad)\n",
    "* If you place interior points close to edges creates the opposite: first step very bad, next step very good\n",
    "* **Solution**: find sweet spot(s) to make sure the search interval is divided by same ratio each time.\n",
    "* See pp. 281-282 of textbook for explanation of why this ratio needs to be $$z = \\frac{1+\\sqrt5}2 \\approx 1.618$$ the *Golden Ratio*.\n",
    "    I.e., $x_4-x_1 = (x_3-x_1)z = (x_4-x_2)z$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Finding solutions of linear systems** $Ax = v$\n",
    "* Gaussian elimination if you know the 1st coefficient will always be OK\n",
    "* Partial pivot to be safe: re-order equations such that biggest first coefficient shows up first\n",
    "* LU decomposition is strictly the same as Partial pivot, but storing $L$ and $U$ saves times when $A$ stays the same but $v$ changes often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Finding eigenvalues/eigenvectors**\n",
    "* Matrix is real symmetric or Hermitian: QR algorithm is iterative (can take time to converge) but efficient.\n",
    "* Otherwise: SciPy will find them for you if patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Finding roots of nonlinear equations**\n",
    "    $$f(x) = 0 \\quad\\text{or}\\quad  f(x)-x=0$$\n",
    "* Relaxation for $f(x)=x$ is easy but works only for stable fixed points\n",
    "* Newton's method is super fast but you need a good initial guess and confidence that a root exists\n",
    "* Binary search is easy, converges slowly, has a lot of caveat (double roots, need a good initial bracket...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Finding minima/maxima**: Golden ratio search, slow and suffers from same limitations as binary search, but works."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
